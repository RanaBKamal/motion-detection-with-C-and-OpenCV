/* Date: 2016 JAN 14 */

//opencv libraries 
#include "opencv2/core/core.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/video/background_segm.hpp"
using namespace cv;

//C++ libraries
#include <iostream>
#include <sstream>
#include <vector>
using namespace std;

//global variables
Mat frame; //current frame
Mat fgMaskMOG2; //foreground mask generated by MOG2 method

Ptr<BackgroundSubtractorMOG2> pMOG2; //MOG Background subtractor
int keyboard;

//to check whether from camera or existing video
static bool isFromCamera = false;

//frame width and height
double FRAME_WIDTH;
double FRAME_HEIGHT;
double AREA_TOLERENCE;

//function declarations
void help(); //functions for the input parameter declarations
void processVideo(char* videoFilename, VideoCapture capture); //this function processes the given video with the videoFilename
void displayObjectNumber(Mat &frameName, int objectNumber);
void trackFilteredObject(int &x, int &y, Mat threshold, Mat &cameraFeed); //function used to track the moving filtered objects

int main(int argc, char* argv[])
{
	
	//for the exception handling using the try catch
	try
	{
		//print help information
	    help();

	    //check for the input parameter correctness
	    if(argc != 2) {
	        cerr <<"Incorret input list" << endl;
	        cerr <<"exiting..." << endl;
	        return EXIT_FAILURE;
	    }

	    //create GUI windows
	    namedWindow("motionDetection");
	    //namedWindow("FG Mask MOG2");

	    //create the substractor object by MOG2 approach
	    pMOG2= new BackgroundSubtractorMOG2(); 
	    
	    //check whether the video is from camera or existing video
	    if (strcmp(argv[1],"cam") == 0)
	    {
	    	isFromCamera = true;

	    	//make the video from the default camera
	    	VideoCapture capture(0);
	    	//process the videos 
	    	processVideo(argv[1],capture);
	    }else{
	    	VideoCapture capture(argv[1]);
	    	//process the videos 
	    	processVideo(argv[1],capture);	
	    }
	    
	    //destroy GUI windows
	    destroyAllWindows();
	    return EXIT_SUCCESS;
	}
	catch( cv::Exception& e ) //catches the exceptions and then displays
	{
	    const char* err_msg = e.what();
	    std::cout << "exception caught: " << err_msg << std::endl;
	}
}

//function to display the number of the object in motion
void displayObjectNumber(Mat &frameName, int objectNumber){
	//count the number of frame and disply        
    stringstream ss;
    rectangle(frameName, cv::Point(0, 0), cv::Point(200,20),
        cv::Scalar(255,255,255), -1);

    ss << objectNumber;
    string strTag = "Objects in motion : ";\
    string obNumber = ss.str();
    string showStr = strTag + obNumber;

    putText(frameName, showStr.c_str(), cv::Point(5, 15),
        FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
}


//function defination of the help() function
void help()
{
    cout
        << "--------------------------------------------------------------------------" << endl
        << "This program is tracking the objects, by using background subtraction "     << endl
        << "methods provided by  OpenCV. You can process videos from file as well as"	<< endl
        << "cameras "	     															<< endl
        << endl
        << "Usage:"                                                                     << endl
        << "for video from file: ./bs <video filename>"                           		<< endl
        << "for example: ./bs video.avi"                                            	<< endl
        << "for video from cameras: ./bs <cam>"			                           		<< endl
        << "for example: ./bs cam"		                                            	<< endl
        << "--------------------------------------------------------------------------" << endl
        << endl;
}


//function defination of the processVideo() function
void processVideo(char* videoFilename,VideoCapture capture) {

	int x = 0,y = 0;
	Mat GRAYCurrrentFrame;
	Mat differenceImage;
	Mat thresholdImage;

    //get width and the height of the video frame
    FRAME_WIDTH = capture.get(CV_CAP_PROP_FRAME_WIDTH);
    FRAME_HEIGHT = capture.get(CV_CAP_PROP_FRAME_HEIGHT);
    AREA_TOLERENCE = FRAME_WIDTH * FRAME_HEIGHT / 10;

    //Detect if there is ERROR in opening the video
    if(!capture.isOpened()){
        cerr << "Unable to open video file: " << videoFilename << endl;
        exit(EXIT_FAILURE);
    }

    //read input data. ESC or 'q' for quitting
    while((char)keyboard != 27 ){
        
        //read the current frame and check for the errors
        if(!capture.read(frame)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            exit(EXIT_FAILURE);
        }

        //update the background model and get the mask
        pMOG2->operator()(frame, fgMaskMOG2);

        if (isFromCamera)
        {
        	//morphological opening (remove small objects from the foreground)
			erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(10, 10)) );
			dilate( fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(10, 10)) ); 

			//morphological closing (fill small holes in the foreground)
			dilate( fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(10, 10)) ); 
			erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(10, 10)) );

			//blur the image
	        blur(fgMaskMOG2,fgMaskMOG2,Size(16,16));
        }else{
        	//morphological opening (remove small objects from the foreground)
			erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );
			dilate( fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) ); 

			//morphological closing (fill small holes in the foreground)
			dilate( fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) ); 
			erode(fgMaskMOG2, fgMaskMOG2, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );

			//blur the image
	        blur(fgMaskMOG2,fgMaskMOG2,Size(10,10));
        }      

        

        //convert the original frame to the GRAY to compare with the foreground mask 
		cvtColor(frame,GRAYCurrrentFrame, COLOR_BGR2GRAY);

		//find the absolute difference between the current frame abd the foreground mask
		//this is just for the future use
		absdiff(GRAYCurrrentFrame,fgMaskMOG2,differenceImage);

        //track the foreground moving objects
        trackFilteredObject(x,y,fgMaskMOG2, frame);

        //show the current frames with the motion tracking
        imshow("motionDetection", frame);

        //get the input from the keyboard
        keyboard = waitKey( 80 );
    }

    //delete capture object
    capture.release();
}

void trackFilteredObject(int &x, int &y, Mat threshold1, Mat &cameraFeed){
	
	Mat temp;
	threshold1.copyTo(temp);

	//these two vectors needed for the output of the findContours
	vector< vector<Point> > contours;
	vector<Vec4i> hierarchy;

	//compute the threshold between the images
	threshold(threshold1,temp,10,255,THRESH_BINARY);

	//find the contours
	findContours(temp, contours, hierarchy,CV_RETR_CCOMP,CV_CHAIN_APPROX_SIMPLE);

	//drawing the rectangular contours for the found objects
	/// Approximate contours to polygons + get bounding rects
  	vector<vector<Point> > contours_poly( contours.size() );
  	vector<Rect> boundRect( contours.size() );

	//use moments method to find out the filtered object
	if (hierarchy.size() > 0)
	{

		int numObjects = hierarchy.size();
		//if the number of objects is greater than 20 probably the noisy filter
		if (numObjects < 500){

			displayObjectNumber(cameraFeed,numObjects);

			for( int i = 0; i < contours.size(); i++ )
		    { 
		    	approxPolyDP( Mat(contours[i]), contours_poly[i], 3, true );
		       	boundRect[i] = boundingRect( Mat(contours_poly[i]) );
		    }

			for (int index = 0; index >= 0; index = hierarchy[index][0])
			{
				Moments moment = moments((Mat)contours[index]);
				double area = moment.m00;

				//just consider the resonable size as the object
				if (area > 14 && area < AREA_TOLERENCE)
				{
					//this is for the positiono of the objects
					//x = moment.m10 / area;
					//y = moment.m01 / area;
					//drawContours( cameraFeed, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point() );

					Scalar color = Scalar(0,0,255);
			       rectangle( cameraFeed, boundRect[index].tl(), boundRect[index].br(), color, 2, 8, 0 );
				}
			}

		}else{

			//for the noisy and moving camera this program will fail to detect moving object
			putText(cameraFeed,"To much noise adjust filter",Point(0,50),2,1,Scalar(0,255,0),2);
		}	
	}
	
}